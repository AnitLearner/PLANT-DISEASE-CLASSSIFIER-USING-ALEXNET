{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO50aYv25ChL/G0wrAmao5R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnitLearner/PLANT-DISEASE-CLASSSIFIER-USING-ALEXNET/blob/main/Traffic_Signal_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGkGg0LVIcoZ",
        "outputId": "c5440aa2-3aea-4716-c768-61a5bf9961e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gtsrb-german-traffic-sign.zip to /content\n",
            " 96% 589M/612M [00:08<00:00, 29.0MB/s]\n",
            "100% 612M/612M [00:08<00:00, 74.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "import os\n",
        "os.environ['KAGGEL_CONFIG_DIR'] = '/content'\n",
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/gtsrb-german-traffic-sign.zip', 'r')\n",
        "zip_ref.extractall('/content/gtsrb-german-traffic-sign')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "np.random.seed(42)\n",
        "\n",
        "from matplotlib import style\n",
        "style.use('fivethirtyeight')"
      ],
      "metadata": {
        "id": "8UUUEnnoI0RH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/content/gtsrb-german-traffic-sign\"\n",
        "train_path = '/content/gtsrb-german-traffic-sign/Train'\n",
        "test_path = '/content/gtsrb-german-traffic-sign/Test'\n",
        "\n",
        "# Resizing the images to 30x30x3\n",
        "IMG_HEIGHT = 30\n",
        "IMG_WIDTH = 30\n",
        "channels = 3\n",
        "NUM_CATEGORIES = len(os.listdir(train_path))\n",
        "NUM_CATEGORIES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtPsvOjkI8VV",
        "outputId": "1ab6a789-f3e6-4874-ddbc-921b2e400c36"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Overview\n",
        "classes = { 0:'Speed limit (20km/h)',\n",
        "            1:'Speed limit (30km/h)',\n",
        "            2:'Speed limit (50km/h)',\n",
        "            3:'Speed limit (60km/h)',\n",
        "            4:'Speed limit (70km/h)',\n",
        "            5:'Speed limit (80km/h)',\n",
        "            6:'End of speed limit (80km/h)',\n",
        "            7:'Speed limit (100km/h)',\n",
        "            8:'Speed limit (120km/h)',\n",
        "            9:'No passing',\n",
        "            10:'No passing veh over 3.5 tons',\n",
        "            11:'Right-of-way at intersection',\n",
        "            12:'Priority road',\n",
        "            13:'Yield',\n",
        "            14:'Stop',\n",
        "            15:'No vehicles',\n",
        "            16:'Veh > 3.5 tons prohibited',\n",
        "            17:'No entry',\n",
        "            18:'General caution',\n",
        "            19:'Dangerous curve left',\n",
        "            20:'Dangerous curve right',\n",
        "            21:'Double curve',\n",
        "            22:'Bumpy road',\n",
        "            23:'Slippery road',\n",
        "            24:'Road narrows on the right',\n",
        "            25:'Road work',\n",
        "            26:'Traffic signals',\n",
        "            27:'Pedestrians',\n",
        "            28:'Children crossing',\n",
        "            29:'Bicycles crossing',\n",
        "            30:'Beware of ice/snow',\n",
        "            31:'Wild animals crossing',\n",
        "            32:'End speed + passing limits',\n",
        "            33:'Turn right ahead',\n",
        "            34:'Turn left ahead',\n",
        "            35:'Ahead only',\n",
        "            36:'Go straight or right',\n",
        "            37:'Go straight or left',\n",
        "            38:'Keep right',\n",
        "            39:'Keep left',\n",
        "            40:'Roundabout mandatory',\n",
        "            41:'End of no passing',\n",
        "            42:'End no passing veh > 3.5 tons' }"
      ],
      "metadata": {
        "id": "kgbOxRQpJBpj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_data = []\n",
        "image_labels = []\n",
        "\n",
        "for i in range(NUM_CATEGORIES):\n",
        "    path = data_dir + '/Train/' + str(i)\n",
        "    images = os.listdir(path)\n",
        "\n",
        "    for img in images:\n",
        "        try:\n",
        "            image = cv2.imread(path + '/' + img)\n",
        "            image_fromarray = Image.fromarray(image, 'RGB')\n",
        "            resize_image = image_fromarray.resize((IMG_HEIGHT, IMG_WIDTH))\n",
        "            image_data.append(np.array(resize_image))\n",
        "            image_labels.append(i)\n",
        "        except:\n",
        "            print(\"Error in \" + img)\n",
        "\n",
        "# Changing the list to numpy array\n",
        "image_data = np.array(image_data)\n",
        "image_labels = np.array(image_labels)\n",
        "\n",
        "print(image_data.shape, image_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmcOXaWnJPZD",
        "outputId": "32ebd590-9bf3-4ef9-d71f-10124b58b9e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(39209, 30, 30, 3) (39209,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Shuffling the training data\n",
        "shuffle_indexes = np.arange(image_data.shape[0])\n",
        "np.random.shuffle(shuffle_indexes)\n",
        "image_data = image_data[shuffle_indexes]\n",
        "image_labels = image_labels[shuffle_indexes]\n",
        "## Splitting the data into train and validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(image_data, image_labels, test_size=0.3, random_state=42, shuffle=True)\n",
        "\n",
        "X_train = X_train/255\n",
        "X_val = X_val/255\n",
        "\n",
        "print(\"X_train.shape\", X_train.shape)\n",
        "print(\"X_valid.shape\", X_val.shape)\n",
        "print(\"y_train.shape\", y_train.shape)\n",
        "print(\"y_valid.shape\", y_val.shape)\n",
        "## One hot encoding the labels\n",
        "y_train = keras.utils.to_categorical(y_train, NUM_CATEGORIES)\n",
        "y_val = keras.utils.to_categorical(y_val, NUM_CATEGORIES)\n",
        "\n",
        "print(\"y_train.shape\",y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vdJEPNlJY3d",
        "outputId": "351b1fdc-f953-438e-91de-855a7278cb5d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape (27446, 30, 30, 3)\n",
            "X_valid.shape (11763, 30, 30, 3)\n",
            "y_train.shape (27446,)\n",
            "y_valid.shape (11763,)\n",
            "y_train.shape (27446, 43)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Conv3D, DepthwiseConv2D, SeparableConv2D, Conv3DTranspose\n",
        "from tensorflow.keras.layers import Flatten, MaxPool2D, AvgPool2D, GlobalAvgPool2D, UpSampling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Concatenate, Add, Dropout, ReLU, Lambda, Activation, LeakyReLU, PReLU"
      ],
      "metadata": {
        "id": "eAiWNxikJdom"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DWS_model_TSR = keras.models.Sequential([\n",
        "                  keras.layers.Conv2D(6, kernel_size=3, strides=1,  activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,channels), padding='same'), #Conv_Layer_1\n",
        "                  #keras.layers.AveragePooling2D(), #S2\n",
        "                  keras.layers.SeparableConv2D(2,kernel_size=3,strides=(1, 1), padding='same',dilation_rate=(1, 1),depth_multiplier=1,activation=None,use_bias=True),#DWSConv_Layer_2\n",
        "                  keras.layers.Conv2D(2, kernel_size=3, strides=1,  activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,channels), padding='same'), # #Conv_Layer_3\n",
        "                  #keras.layers.Conv2D(120, kernel_size=5, strides=1, activation='relu', padding='same'), #C5\n",
        "                  keras.layers.SeparableConv2D(2,kernel_size=3,strides=(1, 1), padding='same',dilation_rate=(1, 1),depth_multiplier=1,activation=None,use_bias=True), #Conv_Layer_4\n",
        "                  keras.layers.MaxPooling2D(), #S2\n",
        "                  keras.layers.MaxPooling2D(), #S2\n",
        "                  keras.layers.Flatten(), #Flatten\n",
        "                  #keras.layers.Dense(20, activation='tanh'), #F6\n",
        "                  keras.layers.Dense(43, activation='softmax') #Output layer\n",
        "                  ])"
      ],
      "metadata": {
        "id": "4w4S4XaiJkGz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "DWS_model_TSR.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "epochs=3\n",
        "# Train the model\n",
        "#history = model.fit(train_x, train_y, epochs=10, validation_data=(val_x, val_y))\n",
        "# prompt: stop training if the there is no significant improvements in accuracy\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "history = DWS_model_TSR.fit(X_train, y_train,  epochs=epochs, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = DWS_model_TSR.predict(X_val)\n",
        "y_pred = y_pred.argmax(axis=-1)\n",
        "y_valn=y_val.argmax(axis=-1)\n",
        "accuracy = accuracy_score(y_valn,y_pred)\n",
        "print('Test Data accuracy: ',accuracy_score(y_valn,y_pred)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5o6PnPtJqJV",
        "outputId": "6ee9f915-9262-4fd2-9e8a-c9b68207bca0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "858/858 [==============================] - 59s 66ms/step - loss: 2.5542 - accuracy: 0.3131 - val_loss: 1.3281 - val_accuracy: 0.6225\n",
            "Epoch 2/3\n",
            "858/858 [==============================] - 48s 56ms/step - loss: 1.0239 - accuracy: 0.6952 - val_loss: 0.8237 - val_accuracy: 0.7528\n",
            "Epoch 3/3\n",
            "858/858 [==============================] - 68s 79ms/step - loss: 0.6902 - accuracy: 0.7942 - val_loss: 0.6048 - val_accuracy: 0.8244\n",
            "368/368 [==============================] - 9s 24ms/step\n",
            "Test Data accuracy:  82.43645328572643\n"
          ]
        }
      ]
    }
  ]
}